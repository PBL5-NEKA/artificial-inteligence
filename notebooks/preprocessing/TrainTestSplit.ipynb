{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:26:28.544081700Z",
     "start_time": "2024-01-15T10:26:18.696349700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rubio\\anaconda3\\envs\\neka\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "WARNING:tensorflow:From C:\\Users\\rubio\\AppData\\Local\\Temp\\ipykernel_5108\\1431907742.py:6: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data and Train Test Split\n",
    "\n",
    "In order to check whether the modelling succeeded (if overfitting didn't occur) a train test split will be made at the beginnig of the process. This way the validation set generated below will be used to simulate unseen data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6289731f9a5f829"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2040 files belonging to 2 classes.\n",
      "Using 1632 files for training.\n",
      "Using 408 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rubio\\anaconda3\\envs\\neka\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_dir='../../data/raw/FinalDataset/'\n",
    "train_set, validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir, # images directory\n",
    "        image_size=(256, 256), # images size\n",
    "        seed=1, # Especifica una semilla para la aleatorización. Esto se usa para garantizar que, si necesitas dividir el conjunto de datos en entrenamiento y validación de manera aleatoria, la división sea reproducible si se usa la misma semilla.\n",
    "        validation_split=0.2, # the percentage of data for validation\n",
    "        subset='both', # Esto significa que se creará un conjunto de datos que contendrá tanto los datos de entrenamiento como los de validación, dividiendo según el porcentaje especificado en validation_split\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:26:29.199980100Z",
     "start_time": "2024-01-15T10:26:28.544081700Z"
    }
   },
   "id": "f6cf4b9847971730"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Data\n",
    "\n",
    "Simply save the comepleted split separetely."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcfbd06180d175bf"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Function to create class folders within the specified directory\n",
    "def create_class_folders(output_dir, classes):\n",
    "    for class_name in classes:\n",
    "        class_path = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(class_path, exist_ok=True)\n",
    "\n",
    "# Function to save images from a dataset to class-specific folders\n",
    "def save_images(dataset, output_dir, classes):\n",
    "    create_class_folders(output_dir, classes)\n",
    "\n",
    "    for _, (images, labels) in enumerate(dataset):\n",
    "        # Process each batch of images\n",
    "        for image, label in zip(images.numpy(), labels.numpy()):\n",
    "            class_name = classes[label]\n",
    "            class_path = os.path.join(output_dir, class_name)\n",
    "            filename = f'image_{len(os.listdir(class_path)) + 1}.png'\n",
    "            filepath = os.path.join(class_path, filename)\n",
    "            \n",
    "            cv2.imwrite(filepath, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:26:29.246236800Z",
     "start_time": "2024-01-15T10:26:29.199980100Z"
    }
   },
   "id": "e435df552b023550"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set images saved to: ../../data/raw/FinalDatasetTrainTest/train/\n",
      "Validation set images saved to: ../../data/raw/FinalDatasetTrainTest/test/\n"
     ]
    }
   ],
   "source": [
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Directories to save the images\n",
    "train_output_dir = '../../data/raw/FinalDatasetTrainTest/train/'\n",
    "val_output_dir = '../../data/raw/FinalDatasetTrainTest/test/'\n",
    "os.makedirs(train_output_dir, exist_ok=True)\n",
    "os.makedirs(val_output_dir, exist_ok=True)\n",
    "\n",
    "class_names = ['Awake', 'Tired']\n",
    "\n",
    "# Save images from the training dataset\n",
    "save_images(train_set, train_output_dir, class_names)\n",
    "\n",
    "# Save images from the validation dataset\n",
    "save_images(validation_set, val_output_dir, class_names)\n",
    "\n",
    "# Optionally, print the paths to the saved images directories\n",
    "print(f\"Train set images saved to: {train_output_dir}\")\n",
    "print(f\"Validation set images saved to: {val_output_dir}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:26:42.008668100Z",
     "start_time": "2024-01-15T10:26:29.215155900Z"
    }
   },
   "id": "131469f17290c74d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
