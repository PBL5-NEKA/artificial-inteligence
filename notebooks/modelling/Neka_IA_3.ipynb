{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlwzTSNE-N2s"
   },
   "source": [
    "# NEKA - Modelling\n",
    "The objective is to say if a driver is tired or not, to avoid car accidents. The idea of this file is to preprocess face images to generate a model which is able to predict drowsiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQzVLyueSLDw"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hegiO1AlSWg_",
    "ExecuteTime": {
     "end_time": "2023-12-21T09:25:02.722865200Z",
     "start_time": "2023-12-21T09:24:49.412984900Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjS547KHUfUA"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "Load the previously preprocessed images, for modelling in further code cells. Data will be loaded and split using the same function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_dir='../../data/Processed'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T09:25:02.749643500Z",
     "start_time": "2023-12-21T09:25:02.715191700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8MTu3cWbx9G",
    "outputId": "e799e0ad-f8e7-434b-a683-b5351bc834c2",
    "ExecuteTime": {
     "end_time": "2023-12-21T09:25:06.123907900Z",
     "start_time": "2023-12-21T09:25:02.744386100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6797 files belonging to 2 classes.\n",
      "Using 5438 files for training.\n",
      "Using 1359 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_set, validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir, #images directory\n",
    "        image_size=(64, 64), #images size\n",
    "        seed=1, # Especifica una semilla para la aleatorización. Esto se usa para garantizar que, si necesitas dividir el conjunto de datos en entrenamiento y validación de manera aleatoria, la división sea reproducible si se usa la misma semilla.\n",
    "        validation_split=0.2, # The percentage of data for validation\n",
    "        subset='both', # Esto significa que se creará un conjunto de datos que contendrá tanto los datos de entrenamiento como los de validación, dividiendo según el porcentaje especificado en validation_split\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w86Pg_tCcg0Z"
   },
   "source": [
    "## Basic Preprocessing\n",
    "\n",
    "This preprocessing will be implemented on other notebook in the near future (check feature-basic-preprocessing branch)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MUXDtzMCckkl",
    "ExecuteTime": {
     "end_time": "2023-12-21T09:25:06.286338700Z",
     "start_time": "2023-12-21T09:25:06.126085400Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = train_set.map(lambda x,y:(x/255,y)) #train normalization\n",
    "validation_set = validation_set.map(lambda x,y:(x/255,y)) #validation normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Y8RZD-ebTv2"
   },
   "source": [
    "### Model with Convolutional Layers and Drop Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9QfRSJb8fwgV",
    "ExecuteTime": {
     "end_time": "2023-12-21T09:25:06.687724700Z",
     "start_time": "2023-12-21T09:25:06.301772100Z"
    }
   },
   "outputs": [],
   "source": [
    "ModeloCNN2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)), # agrega una capa de convolución con 32 filtros de tamaño 3x3, activada por la función de activación ReLU\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), # Agrega una capa de Max Pooling para reducir la dimensionalidad espacial de la salida de la capa convolucional.\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(), # Esta capa aplana la salida de la última capa de convolución (transformándola en un vector unidimensional) para prepararla para las capas densamente conectadas.\n",
    "    tf.keras.layers.Dropout(0.5), # Agrega una capa de Dropout para ayudar a prevenir el sobreajuste, desactivando aleatoriamente el 50% de las neuronas durante el entrenamiento.\n",
    "    tf.keras.layers.Dense(256, activation='relu'), # Una capa densa con 256 neuronas y activación ReLU.\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') # Capa de salida con una sola neurona y activación sigmoide, comúnmente usada para problemas de clasificación binaria.\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0Ua8O6ObeZ6"
   },
   "source": [
    "### Training the CNN Model with Drop Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biAnR5vMeb_u",
    "outputId": "ee6c1dbb-0697-40cf-cba0-76978e696422",
    "ExecuteTime": {
     "end_time": "2023-12-21T09:28:55.551359800Z",
     "start_time": "2023-12-21T09:25:06.694685100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "170/170 [==============================] - 45s 238ms/step - loss: 0.4858 - accuracy: 0.7602 - val_loss: 0.3371 - val_accuracy: 0.8411\n",
      "Epoch 2/10\n",
      "170/170 [==============================] - 22s 127ms/step - loss: 0.3040 - accuracy: 0.8663 - val_loss: 0.2415 - val_accuracy: 0.8918\n",
      "Epoch 3/10\n",
      "170/170 [==============================] - 21s 123ms/step - loss: 0.2272 - accuracy: 0.9005 - val_loss: 0.2317 - val_accuracy: 0.8889\n",
      "Epoch 4/10\n",
      "170/170 [==============================] - 21s 123ms/step - loss: 0.1896 - accuracy: 0.9189 - val_loss: 0.1851 - val_accuracy: 0.9169\n",
      "Epoch 5/10\n",
      "170/170 [==============================] - 21s 121ms/step - loss: 0.1674 - accuracy: 0.9312 - val_loss: 0.1716 - val_accuracy: 0.9242\n",
      "Epoch 6/10\n",
      "170/170 [==============================] - 21s 125ms/step - loss: 0.1514 - accuracy: 0.9373 - val_loss: 0.1598 - val_accuracy: 0.9279\n",
      "Epoch 7/10\n",
      "170/170 [==============================] - 20s 115ms/step - loss: 0.1368 - accuracy: 0.9445 - val_loss: 0.1627 - val_accuracy: 0.9257\n",
      "Epoch 8/10\n",
      "170/170 [==============================] - 19s 113ms/step - loss: 0.1269 - accuracy: 0.9459 - val_loss: 0.1431 - val_accuracy: 0.9419\n",
      "Epoch 9/10\n",
      "170/170 [==============================] - 19s 109ms/step - loss: 0.1191 - accuracy: 0.9487 - val_loss: 0.1472 - val_accuracy: 0.9404\n",
      "Epoch 10/10\n",
      "170/170 [==============================] - 19s 111ms/step - loss: 0.1141 - accuracy: 0.9520 - val_loss: 0.1478 - val_accuracy: 0.9352\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2cefa882670>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "ModeloCNN2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# optimizer='adam': Define el optimizador que se utilizará durante el entrenamiento del modelo. En este caso, se utiliza el optimizador Adam, que es un algoritmo de optimización popular y eficiente para entrenar redes neuronales.\n",
    "#loss='binary_crossentropy': Establece la función de pérdida que se utilizará para evaluar qué tan bien está aprendiendo el modelo durante el entrenamiento. En este caso, se emplea la función de pérdida 'binary_crossentropy', que es comúnmente usada para problemas de clasificación binaria.\n",
    "#metrics=['accuracy']: Especifica las métricas que se utilizarán para evaluar el rendimiento del modelo durante y después del entrenamiento.\n",
    "\n",
    "ModeloCNN2.fit(train_set, epochs=10, batch_size=32, validation_data=validation_set, callbacks=[tensorboard_callback])\n",
    "#train_set: Este es el conjunto de datos de entrenamiento que se utiliza para ajustar los pesos del modelo.\n",
    "#epochs=10: Indica la cantidad de veces que todo el conjunto de datos de entrenamiento se pasará hacia adelante y hacia atrás a través de la red neuronal durante el entrenamiento.\n",
    "#batch_size=32: Especifica el número de muestras que se utilizan en cada iteración de entrenamiento. El modelo se actualiza después de cada lote. En este caso, se utiliza un tamaño de lote de 32.\n",
    "#validation_data=validation_set: Aquí se proporciona el conjunto de datos de validación para evaluar el rendimiento del modelo en datos que no se utilizan en el entrenamiento. Esto ayuda a monitorear si el modelo está sobreajustando o generalizando bien.\n",
    "#callbacks=[tensorboard_callback]: Los callbacks son funciones que se llaman durante el entrenamiento en diferentes etapas. En este caso, se utiliza tensorboard_callback, que probablemente sea un objeto que se utiliza para guardar información de entrenamiento para su visualización en TensorBoard, una herramienta de visualización de TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the model"
   ],
   "metadata": {
    "id": "CFRsZrwBdeCZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JFXxYW3de8df",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ce5ee802-8d15-4b58-cf8b-d35ecbe4bb70",
    "ExecuteTime": {
     "end_time": "2023-12-21T09:28:55.807532400Z",
     "start_time": "2023-12-21T09:28:55.568602700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "ModeloCNN2.save('../../models/Neka_IA_model.h5') # To save model --->.h5 format\n",
    "ModeloCNN2.save_weights('../../models/Neka_pesosIA.h5') # Esto no guarda la arquitectura o la configuración del modelo, solo los valores numéricos de los pesos que han sido aprendidos durante el entrenamiento.\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Additional Information\n",
    "\n",
    "### Weights\n",
    "\n",
    " En una CNN, los pesos son matrices numéricas que representan la importancia y la relación entre las diferentes características (como bordes, texturas, etc.) presentes en las imágenes o datos de entrada.\n",
    "\n",
    "Los pesos se utilizan en las capas de la red neuronal para realizar operaciones matemáticas en los datos de entrada y producir salidas que se acerquen lo más posible a las salidas deseadas. Estos pesos son ajustados iterativamente durante el entrenamiento para minimizar la diferencia entre las predicciones del modelo y las etiquetas reales de los datos de entrenamiento."
   ],
   "metadata": {
    "id": "Rlt1EYIhMwZW"
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "pQzVLyueSLDw",
    "bjS547KHUfUA"
   ],
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
